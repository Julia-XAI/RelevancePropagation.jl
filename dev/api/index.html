<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>API Reference · RelevancePropagation.jl</title><meta name="title" content="API Reference · RelevancePropagation.jl"/><meta property="og:title" content="API Reference · RelevancePropagation.jl"/><meta property="twitter:title" content="API Reference · RelevancePropagation.jl"/><meta name="description" content="Documentation for RelevancePropagation.jl."/><meta property="og:description" content="Documentation for RelevancePropagation.jl."/><meta property="twitter:description" content="Documentation for RelevancePropagation.jl."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="RelevancePropagation.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">RelevancePropagation.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><span class="tocitem">Basic Usage</span><ul><li><a class="tocitem" href="../generated/basics/">Creating an LRP Analyzer</a></li><li><a class="tocitem" href="../generated/composites/">Assigning Rules to Layers</a></li><li><a class="tocitem" href="../generated/crp/">Concept Relevance Propagation</a></li></ul></li><li><span class="tocitem">Advanced Usage</span><ul><li><a class="tocitem" href="../generated/custom_layer/">Supporting New Layer Types</a></li><li><a class="tocitem" href="../generated/custom_rules/">Custom LRP Rules</a></li><li><a class="tocitem" href="../developer/">Developer Documentation</a></li></ul></li><li><a class="tocitem" href="../rules/">LRP Rule Overview</a></li><li class="is-active"><a class="tocitem" href>API Reference</a><ul class="internal"><li><a class="tocitem" href="#Basic-API"><span>Basic API</span></a></li><li><a class="tocitem" href="#LRP-analyzer"><span>LRP analyzer</span></a></li><li><a class="tocitem" href="#LRP-rules"><span>LRP rules</span></a></li><li><a class="tocitem" href="#Composites"><span>Composites</span></a></li><li><a class="tocitem" href="#Custom-rules"><span>Custom rules</span></a></li><li><a class="tocitem" href="#CRP"><span>CRP</span></a></li><li class="toplevel"><a class="tocitem" href="#Index"><span>Index</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>API Reference</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>API Reference</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/Julia-XAI/RelevancePropagation.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/main/docs/src/api.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="API-Reference"><a class="docs-heading-anchor" href="#API-Reference">API Reference</a><a id="API-Reference-1"></a><a class="docs-heading-anchor-permalink" href="#API-Reference" title="Permalink"></a></h1><h2 id="Basic-API"><a class="docs-heading-anchor" href="#Basic-API">Basic API</a><a id="Basic-API-1"></a><a class="docs-heading-anchor-permalink" href="#Basic-API" title="Permalink"></a></h2><p>All methods in RelevancePropagation.jl work by calling <code>analyze</code> on an input and an analyzer:</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="XAIBase.analyze" href="#XAIBase.analyze"><code>XAIBase.analyze</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">analyze(input, method)
analyze(input, method, output_selection)</code></pre><p>Apply the analyzer <code>method</code> for the given input, returning an <a href="#XAIBase.Explanation"><code>Explanation</code></a>. If <code>output_selection</code> is specified, the explanation will be calculated for that output. Otherwise, the output with the highest activation is automatically chosen.</p><p>See also <a href="#XAIBase.Explanation"><code>Explanation</code></a>.</p><p><strong>Keyword arguments</strong></p><ul><li><code>add_batch_dim</code>: add batch dimension to the input without allocating. Default is <code>false</code>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/XAIBase.jl/blob/v3.0.0/src/analyze.jl#L7-L19">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="XAIBase.Explanation" href="#XAIBase.Explanation"><code>XAIBase.Explanation</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Explanation(val, output, output_selection, analyzer, heatmap, extras)</code></pre><p>Return type of analyzers when calling <a href="#XAIBase.analyze"><code>analyze</code></a>.</p><p><strong>Fields</strong></p><ul><li><code>val</code>: numerical output of the analyzer, e.g. an attribution or gradient</li><li><code>output</code>: model output for the given analyzer input</li><li><code>output_selection</code>: index of the output used for the explanation</li><li><code>analyzer</code>: symbol corresponding the used analyzer, e.g. <code>:Gradient</code> or <code>:LRP</code></li><li><code>heatmap</code>: symbol indicating a preset heatmapping style,   e.g. <code>:attribution</code>, <code>:sensitivity</code> or <code>:cam</code></li><li><code>extras</code>: optional named tuple that can be used by analyzers   to return additional information.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/XAIBase.jl/blob/v3.0.0/src/explanation.jl#L1-L15">source</a></section></article><p>For heatmapping functionality, take a look at either <a href="https://julia-xai.github.io/XAIDocs/VisionHeatmaps/stable/">VisionHeatmaps.jl</a> or <a href="https://julia-xai.github.io/XAIDocs/TextHeatmaps/stable/">TextHeatmaps.jl</a>. Both provide <code>heatmap</code> methods for visualizing explanations,  either for images or text, respectively.</p><h2 id="LRP-analyzer"><a class="docs-heading-anchor" href="#LRP-analyzer">LRP analyzer</a><a id="LRP-analyzer-1"></a><a class="docs-heading-anchor-permalink" href="#LRP-analyzer" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.LRP" href="#RelevancePropagation.LRP"><code>RelevancePropagation.LRP</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">LRP(model, rules)
LRP(model, composite)</code></pre><p>Analyze model by applying Layer-Wise Relevance Propagation. The analyzer can either be created by passing an array of LRP-rules or by passing a composite, see <a href="#RelevancePropagation.Composite"><code>Composite</code></a> for an example.</p><p><strong>Keyword arguments</strong></p><ul><li><code>skip_checks::Bool</code>: Skip checks whether model is compatible with LRP and contains output softmax. Default is <code>false</code>.</li><li><code>verbose::Bool</code>: Select whether the model checks should print a summary on failure. Default is <code>true</code>.</li></ul><p><strong>References</strong></p><p>[1] G. Montavon et al., Layer-Wise Relevance Propagation: An Overview [2] W. Samek et al., Explaining Deep Neural Networks and Beyond: A Review of Methods and Applications</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/lrp.jl#L5-L20">source</a></section></article><h3 id="Model-preparation"><a class="docs-heading-anchor" href="#Model-preparation">Model preparation</a><a id="Model-preparation-1"></a><a class="docs-heading-anchor-permalink" href="#Model-preparation" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.strip_softmax" href="#RelevancePropagation.strip_softmax"><code>RelevancePropagation.strip_softmax</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">strip_softmax(model)
strip_softmax(layer)</code></pre><p>Remove softmax activation on layer or model if it exists.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/chain_utils.jl#L256-L261">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.canonize" href="#RelevancePropagation.canonize"><code>RelevancePropagation.canonize</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">canonize(model)</code></pre><p>Canonize model by flattening it and fusing BatchNorm layers into preceding Dense and Conv layers with linear activation functions.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/canonize.jl#L5-L10">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.flatten_model" href="#RelevancePropagation.flatten_model"><code>RelevancePropagation.flatten_model</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">flatten_model(model)</code></pre><p>Flatten a Flux <code>Chain</code> containing <code>Chain</code>s.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/chain_utils.jl#L178-L182">source</a></section></article><h2 id="LRP-rules"><a class="docs-heading-anchor" href="#LRP-rules">LRP rules</a><a id="LRP-rules-1"></a><a class="docs-heading-anchor-permalink" href="#LRP-rules" title="Permalink"></a></h2><p>Refer to the <a href="../rules/#rules">LRP rule overview</a> for a detailed explanation  of the notation used for LRP rules.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.ZeroRule" href="#RelevancePropagation.ZeroRule"><code>RelevancePropagation.ZeroRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ZeroRule()</code></pre><p>LRP-<span>$0$</span> rule. Commonly used on upper layers.</p><p><strong>Definition</strong></p><p>Propagates relevance <span>$R^{k+1}$</span> at layer output to <span>$R^k$</span> at layer input according to</p><p class="math-container">\[R_j^k = \sum_i \frac{W_{ij}a_j^k}{\sum_l W_{il}a_l^k+b_i} R_i^{k+1}\]</p><p><strong>References</strong></p><ul><li>S. Bach et al., <em>On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation</em></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/rules.jl#L153-L166">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.EpsilonRule" href="#RelevancePropagation.EpsilonRule"><code>RelevancePropagation.EpsilonRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">EpsilonRule([epsilon=1.0e-6])</code></pre><p>LRP-<span>$ϵ$</span> rule. Commonly used on middle layers.</p><p><strong>Definition</strong></p><p>Propagates relevance <span>$R^{k+1}$</span> at layer output to <span>$R^k$</span> at layer input according to</p><p class="math-container">\[R_j^k = \sum_i\frac{W_{ij}a_j^k}{\epsilon +\sum_{l}W_{il}a_l^k+b_i} R_i^{k+1}\]</p><p><strong>Optional arguments</strong></p><ul><li><code>epsilon</code>: Optional stabilization parameter, defaults to <code>1.0e-6</code>.</li></ul><p><strong>References</strong></p><ul><li>S. Bach et al., <em>On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation</em></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/rules.jl#L170-L186">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.GammaRule" href="#RelevancePropagation.GammaRule"><code>RelevancePropagation.GammaRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">GammaRule([gamma=0.25])</code></pre><p>LRP-<span>$γ$</span> rule. Commonly used on lower layers.</p><p><strong>Definition</strong></p><p>Propagates relevance <span>$R^{k+1}$</span> at layer output to <span>$R^k$</span> at layer input according to</p><p class="math-container">\[R_j^k = \sum_i\frac{(W_{ij}+\gamma W_{ij}^+)a_j^k}
    {\sum_l(W_{il}+\gamma W_{il}^+)a_l^k+(b_i+\gamma b_i^+)} R_i^{k+1}\]</p><p><strong>Optional arguments</strong></p><ul><li><code>gamma</code>: Optional multiplier for added positive weights, defaults to <code>0.25</code>.</li></ul><p><strong>References</strong></p><ul><li>G. Montavon et al., <em>Layer-Wise Relevance Propagation: An Overview</em></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/rules.jl#L194-L211">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.WSquareRule" href="#RelevancePropagation.WSquareRule"><code>RelevancePropagation.WSquareRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">WSquareRule()</code></pre><p>LRP-<span>$w²$</span> rule. Commonly used on the first layer when values are unbounded.</p><p><strong>Definition</strong></p><p>Propagates relevance <span>$R^{k+1}$</span> at layer output to <span>$R^k$</span> at layer input according to</p><p class="math-container">\[R_j^k = \sum_i\frac{W_{ij}^2}{\sum_l W_{il}^2} R_i^{k+1}\]</p><p><strong>References</strong></p><ul><li>G. Montavon et al., <em>Explaining Nonlinear Classification Decisions with Deep Taylor Decomposition</em></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/rules.jl#L232-L245">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.FlatRule" href="#RelevancePropagation.FlatRule"><code>RelevancePropagation.FlatRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">FlatRule()</code></pre><p>LRP-Flat rule. Similar to the <a href="#RelevancePropagation.WSquareRule"><code>WSquareRule</code></a>, but with all weights set to one and all bias terms set to zero.</p><p><strong>Definition</strong></p><p>Propagates relevance <span>$R^{k+1}$</span> at layer output to <span>$R^k$</span> at layer input according to</p><p class="math-container">\[R_j^k = \sum_i\frac{1}{\sum_l 1} R_i^{k+1} = \sum_i\frac{1}{n_i} R_i^{k+1}\]</p><p>where <span>$n_i$</span> is the number of input neurons connected to the output neuron at index <span>$i$</span>.</p><p><strong>References</strong></p><ul><li>S. Lapuschkin et al., <em>Unmasking Clever Hans predictors and assessing what machines really learn</em></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/rules.jl#L251-L266">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.AlphaBetaRule" href="#RelevancePropagation.AlphaBetaRule"><code>RelevancePropagation.AlphaBetaRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">AlphaBetaRule([alpha=2.0, beta=1.0])</code></pre><p>LRP-<span>$αβ$</span> rule. Weights positive and negative contributions according to the parameters <code>alpha</code> and <code>beta</code> respectively. The difference <span>$α-β$</span> must be equal to one. Commonly used on lower layers.</p><p><strong>Definition</strong></p><p>Propagates relevance <span>$R^{k+1}$</span> at layer output to <span>$R^k$</span> at layer input according to</p><p class="math-container">\[R_j^k = \sum_i\left(
    \alpha\frac{\left(W_{ij}a_j^k\right)^+}{\sum_l\left(W_{il}a_l^k+b_i\right)^+}
    -\beta\frac{\left(W_{ij}a_j^k\right)^-}{\sum_l\left(W_{il}a_l^k+b_i\right)^-}
\right) R_i^{k+1}\]</p><p><strong>Optional arguments</strong></p><ul><li><code>alpha</code>: Multiplier for the positive output term, defaults to <code>2.0</code>.</li><li><code>beta</code>: Multiplier for the negative output term, defaults to <code>1.0</code>.</li></ul><p><strong>References</strong></p><ul><li>S. Bach et al., <em>On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation</em></li><li>G. Montavon et al., <em>Layer-Wise Relevance Propagation: An Overview</em></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/rules.jl#L357-L380">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.ZPlusRule" href="#RelevancePropagation.ZPlusRule"><code>RelevancePropagation.ZPlusRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ZPlusRule()</code></pre><p>LRP-<span>$z⁺$</span> rule. Commonly used on lower layers.</p><p>Equivalent to <code>AlphaBetaRule(1.0f0, 0.0f0)</code>, but slightly faster. See also <a href="#RelevancePropagation.AlphaBetaRule"><code>AlphaBetaRule</code></a>.</p><p><strong>Definition</strong></p><p>Propagates relevance <span>$R^{k+1}$</span> at layer output to <span>$R^k$</span> at layer input according to</p><p class="math-container">\[R_j^k = \sum_i\frac{\left(W_{ij}a_j^k\right)^+}{\sum_l\left(W_{il}a_l^k+b_i\right)^+} R_i^{k+1}\]</p><p><strong>References</strong></p><ul><li>S. Bach et al., <em>On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation</em></li><li>G. Montavon et al., <em>Explaining Nonlinear Classification Decisions with Deep Taylor Decomposition</em></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/rules.jl#L423-L440">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.ZBoxRule" href="#RelevancePropagation.ZBoxRule"><code>RelevancePropagation.ZBoxRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ZBoxRule(low, high)</code></pre><p>LRP-<span>$zᴮ$</span>-rule. Commonly used on the first layer for pixel input.</p><p>The parameters <code>low</code> and <code>high</code> should be set to the lower and upper bounds of the input features, e.g. <code>0.0</code> and <code>1.0</code> for raw image data. It is also possible to provide two arrays of that match the input size.</p><p><strong>Definition</strong></p><p>Propagates relevance <span>$R^{k+1}$</span> at layer output to <span>$R^k$</span> at layer input according to</p><p class="math-container">\[R_j^k=\sum_i \frac{W_{ij}a_j^k - W_{ij}^{+}l_j - W_{ij}^{-}h_j}
    {\sum_l W_{il}a_l^k+b_i - \left(W_{il}^{+}l_l+b_i^{+}\right) - \left(W_{il}^{-}h_l+b_i^{-}\right)} R_i^{k+1}\]</p><p><strong>References</strong></p><ul><li>G. Montavon et al., <em>Layer-Wise Relevance Propagation: An Overview</em></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/rules.jl#L306-L324">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.PassRule" href="#RelevancePropagation.PassRule"><code>RelevancePropagation.PassRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">PassRule()</code></pre><p>Pass-through rule. Passes relevance through to the lower layer.</p><p>Supports layers with constant input and output shapes, e.g. reshaping layers.</p><p><strong>Definition</strong></p><p>Propagates relevance <span>$R^{k+1}$</span> at layer output to <span>$R^k$</span> at layer input according to</p><p class="math-container">\[R_j^k = R_j^{k+1}\]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/rules.jl#L280-L292">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.GeneralizedGammaRule" href="#RelevancePropagation.GeneralizedGammaRule"><code>RelevancePropagation.GeneralizedGammaRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">GeneralizedGammaRule([gamma=0.25])</code></pre><p>Generalized LRP-<span>$γ$</span> rule. Can be used on layers with <code>leakyrelu</code> activation functions.</p><p><strong>Definition</strong></p><p>Propagates relevance <span>$R^{k+1}$</span> at layer output to <span>$R^k$</span> at layer input according to</p><p class="math-container">\[R_j^k = \sum_i\frac
    {(W_{ij}+\gamma W_{ij}^+)a_j^+ +(W_{ij}+\gamma W_{ij}^-)a_j^-}
    {\sum_l(W_{il}+\gamma W_{il}^+)a_j^+ +(W_{il}+\gamma W_{il}^-)a_j^- +(b_i+\gamma b_i^+)}
I(z_k&gt;0) \cdot R^{k+1}_i
+\sum_i\frac
    {(W_{ij}+\gamma W_{ij}^-)a_j^+ +(W_{ij}+\gamma W_{ij}^+)a_j^-}
    {\sum_l(W_{il}+\gamma W_{il}^-)a_j^+ +(W_{il}+\gamma W_{il}^+)a_j^- +(b_i+\gamma b_i^-)}
I(z_k&lt;0) \cdot R^{k+1}_i\]</p><p><strong>Optional arguments</strong></p><ul><li><code>gamma</code>: Optional multiplier for added positive weights, defaults to <code>0.25</code>.</li></ul><p><strong>References</strong></p><ul><li>L. Andéol et al., <em>Learning Domain Invariant Representations by Joint Wasserstein Distance Minimization</em></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/rules.jl#L462-L485">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.LayerNormRule" href="#RelevancePropagation.LayerNormRule"><code>RelevancePropagation.LayerNormRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">LayerNormRule()</code></pre><p>LRP-LN rule. Used on <code>LayerNorm</code> layers.</p><p><strong>Definition</strong></p><p>Propagates relevance <span>$R^{k+1}$</span> at layer output to <span>$R^k$</span> at layer input according to</p><p class="math-container">\[R_i^k = \sum_j\frac{a_i^k\left(\delta_{ij} - 1/N\right)}{\sum_l a_l^k\left(\delta_{lj}-1/N\right)} R_j^{k+1}\]</p><p>Relevance through the affine transformation is by default propagated using the <a href="#RelevancePropagation.ZeroRule"><code>ZeroRule</code></a>.</p><p>If you would like to assign a special rule to the affine transformation inside of the <code>LayerNorm</code> layer, call <code>canonize</code> on your model. This will split the <code>LayerNorm</code> layer into</p><ol><li>a <code>LayerNorm</code> layer without affine transformation</li><li>a <code>Scale</code> layer implementing the affine transformation</li></ol><p>You can then assign separate rules to these two layers.</p><p><strong>References</strong></p><ul><li>A. Ali et al., <em>XAI for Transformers: Better Explanations through Conservative Propagation</em></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/rules.jl#L522-L543">source</a></section></article><h2 id="Composites"><a class="docs-heading-anchor" href="#Composites">Composites</a><a id="Composites-1"></a><a class="docs-heading-anchor-permalink" href="#Composites" title="Permalink"></a></h2><h3 id="Applying-composites"><a class="docs-heading-anchor" href="#Applying-composites">Applying composites</a><a id="Applying-composites-1"></a><a class="docs-heading-anchor-permalink" href="#Applying-composites" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.Composite" href="#RelevancePropagation.Composite"><code>RelevancePropagation.Composite</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Composite(primitives...)
Composite(default_rule, primitives...)</code></pre><p>Automatically contructs a list of LRP-rules by sequentially applying composite primitives.</p><p><strong>Primitives</strong></p><p>To apply a single rule, use:</p><ul><li><a href="#RelevancePropagation.LayerMap"><code>LayerMap</code></a> to apply a rule to the <code>n</code>-th layer of a model</li><li><a href="#RelevancePropagation.GlobalMap"><code>GlobalMap</code></a> to apply a rule to all layers</li><li><a href="#RelevancePropagation.RangeMap"><code>RangeMap</code></a> to apply a rule to a positional range of layers</li><li><a href="#RelevancePropagation.FirstLayerMap"><code>FirstLayerMap</code></a> to apply a rule to the first layer</li><li><a href="#RelevancePropagation.LastLayerMap"><code>LastLayerMap</code></a> to apply a rule to the last layer</li></ul><p>To apply a set of rules to layers based on their type, use:</p><ul><li><a href="#RelevancePropagation.GlobalTypeMap"><code>GlobalTypeMap</code></a> to apply a dictionary that maps layer types to LRP-rules</li><li><a href="#RelevancePropagation.RangeTypeMap"><code>RangeTypeMap</code></a> for a <code>TypeMap</code> on generalized ranges</li><li><a href="#RelevancePropagation.FirstLayerTypeMap"><code>FirstLayerTypeMap</code></a> for a <code>TypeMap</code> on the first layer of a model</li><li><a href="#RelevancePropagation.LastLayerTypeMap"><code>LastLayerTypeMap</code></a> for a <code>TypeMap</code> on the last layer</li><li><a href="#RelevancePropagation.FirstNTypeMap"><code>FirstNTypeMap</code></a> for a <code>TypeMap</code> on the first <code>n</code> layers</li></ul><p><strong>Example</strong></p><p>Using a VGG11 model:</p><pre><code class="language-julia-repl hljs">julia&gt; composite = Composite(
           GlobalTypeMap(
               ConvLayer =&gt; AlphaBetaRule(),
               Dense =&gt; EpsilonRule(),
               PoolingLayer =&gt; EpsilonRule(),
               DropoutLayer =&gt; PassRule(),
               ReshapingLayer =&gt; PassRule(),
           ),
           FirstNTypeMap(7, Conv =&gt; FlatRule()),
       );

julia&gt; analyzer = LRP(model, composite)
LRP(
  Conv((3, 3), 3 =&gt; 64, relu, pad=1)    =&gt; FlatRule(),
  MaxPool((2, 2))                       =&gt; EpsilonRule{Float32}(1.0f-6),
  Conv((3, 3), 64 =&gt; 128, relu, pad=1)  =&gt; FlatRule(),
  MaxPool((2, 2))                       =&gt; EpsilonRule{Float32}(1.0f-6),
  Conv((3, 3), 128 =&gt; 256, relu, pad=1) =&gt; FlatRule(),
  Conv((3, 3), 256 =&gt; 256, relu, pad=1) =&gt; FlatRule(),
  MaxPool((2, 2))                       =&gt; EpsilonRule{Float32}(1.0f-6),
  Conv((3, 3), 256 =&gt; 512, relu, pad=1) =&gt; AlphaBetaRule{Float32}(2.0f0, 1.0f0),
  Conv((3, 3), 512 =&gt; 512, relu, pad=1) =&gt; AlphaBetaRule{Float32}(2.0f0, 1.0f0),
  MaxPool((2, 2))                       =&gt; EpsilonRule{Float32}(1.0f-6),
  Conv((3, 3), 512 =&gt; 512, relu, pad=1) =&gt; AlphaBetaRule{Float32}(2.0f0, 1.0f0),
  Conv((3, 3), 512 =&gt; 512, relu, pad=1) =&gt; AlphaBetaRule{Float32}(2.0f0, 1.0f0),
  MaxPool((2, 2))                       =&gt; EpsilonRule{Float32}(1.0f-6),
  MLUtils.flatten                       =&gt; PassRule(),
  Dense(25088 =&gt; 4096, relu)            =&gt; EpsilonRule{Float32}(1.0f-6),
  Dropout(0.5)                          =&gt; PassRule(),
  Dense(4096 =&gt; 4096, relu)             =&gt; EpsilonRule{Float32}(1.0f-6),
  Dropout(0.5)                          =&gt; PassRule(),
  Dense(4096 =&gt; 1000)                   =&gt; EpsilonRule{Float32}(1.0f-6),
)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/composite.jl#L215-L273">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.lrp_rules" href="#RelevancePropagation.lrp_rules"><code>RelevancePropagation.lrp_rules</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">lrp_rules(model, composite)</code></pre><p>Apply a composite to obtain LRP-rules for a given Flux model.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/composite.jl#L171-L175">source</a></section></article><h3 id="api-composite-primitives"><a class="docs-heading-anchor" href="#api-composite-primitives">Composite primitives</a><a id="api-composite-primitives-1"></a><a class="docs-heading-anchor-permalink" href="#api-composite-primitives" title="Permalink"></a></h3><h4 id="Mapping-layers-to-rules"><a class="docs-heading-anchor" href="#Mapping-layers-to-rules">Mapping layers to rules</a><a id="Mapping-layers-to-rules-1"></a><a class="docs-heading-anchor-permalink" href="#Mapping-layers-to-rules" title="Permalink"></a></h4><p>Composite primitives that apply a single rule:</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.LayerMap" href="#RelevancePropagation.LayerMap"><code>RelevancePropagation.LayerMap</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">LayerMap(index, rule)</code></pre><p>Composite primitive that maps an LRP-rule to all layers in the model at the given index. The index can either be an integer or a tuple of integers to map a rule to a specific layer in nested Flux <code>Chain</code>s.</p><p>See <a href="#RelevancePropagation.show_layer_indices"><code>show_layer_indices</code></a> to print layer indices and <a href="#RelevancePropagation.Composite"><code>Composite</code></a> for an example.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/composite.jl#L31-L39">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.GlobalMap" href="#RelevancePropagation.GlobalMap"><code>RelevancePropagation.GlobalMap</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">GlobalMap(rule)</code></pre><p>Composite primitive that maps an LRP-rule to all layers in the model.</p><p>See <a href="#RelevancePropagation.Composite"><code>Composite</code></a> for an example.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/composite.jl#L20-L26">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.RangeMap" href="#RelevancePropagation.RangeMap"><code>RelevancePropagation.RangeMap</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">RangeMap(range, rule)</code></pre><p>Composite primitive that maps an LRP-rule to the specified positional <code>range</code> of layers in the model.</p><p>See <a href="#RelevancePropagation.Composite"><code>Composite</code></a> for an example.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/composite.jl#L46-L53">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.FirstLayerMap" href="#RelevancePropagation.FirstLayerMap"><code>RelevancePropagation.FirstLayerMap</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">FirstLayerMap(rule)</code></pre><p>Composite primitive that maps an LRP-rule to the first layer in the model.</p><p>See <a href="#RelevancePropagation.Composite"><code>Composite</code></a> for an example.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/composite.jl#L59-L65">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.LastLayerMap" href="#RelevancePropagation.LastLayerMap"><code>RelevancePropagation.LastLayerMap</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">LastLayerMap(rule)</code></pre><p>Composite primitive that maps an LRP-rule to the last layer in the model.</p><p>See <a href="#RelevancePropagation.Composite"><code>Composite</code></a> for an example.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/composite.jl#L70-L76">source</a></section></article><p>To apply <code>LayerMap</code> to nested Flux Chains or <code>Parallel</code> layers,  make use of <code>show_layer_indices</code>:</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.show_layer_indices" href="#RelevancePropagation.show_layer_indices"><code>RelevancePropagation.show_layer_indices</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">show_layer_indices(model)</code></pre><p>Print layer indices of Flux models. This is primarily a utility to help define <a href="#RelevancePropagation.LayerMap"><code>LayerMap</code></a> primitives.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/modelindex.jl#L77-L82">source</a></section></article><h4 id="Mapping-layers-to-rules-based-on-type"><a class="docs-heading-anchor" href="#Mapping-layers-to-rules-based-on-type">Mapping layers to rules based on type</a><a id="Mapping-layers-to-rules-based-on-type-1"></a><a class="docs-heading-anchor-permalink" href="#Mapping-layers-to-rules-based-on-type" title="Permalink"></a></h4><p>Composite primitives that apply rules based on the layer type:</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.GlobalTypeMap" href="#RelevancePropagation.GlobalTypeMap"><code>RelevancePropagation.GlobalTypeMap</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">GlobalTypeMap(map)</code></pre><p>Composite primitive that maps layer types to LRP rules based on a list of type-rule-pairs <code>map</code>.</p><p>See <a href="#RelevancePropagation.Composite"><code>Composite</code></a> for an example.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/composite.jl#L88-L95">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.RangeTypeMap" href="#RelevancePropagation.RangeTypeMap"><code>RelevancePropagation.RangeTypeMap</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">RangeTypeMap(range, map)</code></pre><p>Composite primitive that maps layer types to LRP rules based on a list of type-rule-pairs <code>map</code> within the specified <code>range</code> of layers in the model.</p><p>See <a href="#RelevancePropagation.Composite"><code>Composite</code></a> for an example.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/composite.jl#L100-L107">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.FirstLayerTypeMap" href="#RelevancePropagation.FirstLayerTypeMap"><code>RelevancePropagation.FirstLayerTypeMap</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">FirstLayerTypeMap(map)</code></pre><p>Composite primitive that maps the type of the first layer of the model to LRP rules based on a list of type-rule-pairs <code>map</code>.</p><p>See <a href="#RelevancePropagation.Composite"><code>Composite</code></a> for an example.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/composite.jl#L127-L134">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.LastLayerTypeMap" href="#RelevancePropagation.LastLayerTypeMap"><code>RelevancePropagation.LastLayerTypeMap</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">LastLayerTypeMap(map)</code></pre><p>Composite primitive that maps the type of the last layer of the model to LRP rules based on a list of type-rule-pairs <code>map</code>.</p><p>See <a href="#RelevancePropagation.Composite"><code>Composite</code></a> for an example.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/composite.jl#L139-L146">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.FirstNTypeMap" href="#RelevancePropagation.FirstNTypeMap"><code>RelevancePropagation.FirstNTypeMap</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">FirstNTypeMap(n, map)</code></pre><p>Composite primitive that maps layer types to LRP rules based on a list of type-rule-pairs <code>map</code> within the first <code>n</code> layers in the model.</p><p>See <a href="#RelevancePropagation.Composite"><code>Composite</code></a> for an example.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/composite.jl#L114-L121">source</a></section></article><h4 id="Union-types-for-composites"><a class="docs-heading-anchor" href="#Union-types-for-composites">Union types for composites</a><a id="Union-types-for-composites-1"></a><a class="docs-heading-anchor-permalink" href="#Union-types-for-composites" title="Permalink"></a></h4><p>The following exported union types types can be used to define TypeMaps:</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.ConvLayer" href="#RelevancePropagation.ConvLayer"><code>RelevancePropagation.ConvLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Union type for convolutional layers.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/layer_types.jl#L4">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.PoolingLayer" href="#RelevancePropagation.PoolingLayer"><code>RelevancePropagation.PoolingLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Union type for pooling layers.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/layer_types.jl#L19">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.DropoutLayer" href="#RelevancePropagation.DropoutLayer"><code>RelevancePropagation.DropoutLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Union type for dropout layers.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/layer_types.jl#L7">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.ReshapingLayer" href="#RelevancePropagation.ReshapingLayer"><code>RelevancePropagation.ReshapingLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Union type for reshaping layers such as <code>flatten</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/layer_types.jl#L10">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.NormalizationLayer" href="#RelevancePropagation.NormalizationLayer"><code>RelevancePropagation.NormalizationLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Union type for normalization layers.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/layer_types.jl#L22">source</a></section></article><h3 id="api-composite-presets"><a class="docs-heading-anchor" href="#api-composite-presets">Composite presets</a><a id="api-composite-presets-1"></a><a class="docs-heading-anchor-permalink" href="#api-composite-presets" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.EpsilonGammaBox" href="#RelevancePropagation.EpsilonGammaBox"><code>RelevancePropagation.EpsilonGammaBox</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">EpsilonGammaBox(low, high; [epsilon=1.0f-6, gamma=0.25f0])</code></pre><p>Composite using the following primitives:</p><pre><code class="language-julia-repl hljs">julia&gt; EpsilonGammaBox(-3.0f0, 3.0f0)
Composite(
  GlobalTypeMap(  # all layers
    Flux.Conv               =&gt; RelevancePropagation.GammaRule{Float32}(0.25f0),
    Flux.ConvTranspose      =&gt; RelevancePropagation.GammaRule{Float32}(0.25f0),
    Flux.CrossCor           =&gt; RelevancePropagation.GammaRule{Float32}(0.25f0),
    Flux.Dense              =&gt; RelevancePropagation.EpsilonRule{Float32}(1.0f-6),
    Flux.Scale              =&gt; RelevancePropagation.EpsilonRule{Float32}(1.0f-6),
    Flux.LayerNorm          =&gt; RelevancePropagation.LayerNormRule(),
    typeof(NNlib.dropout)   =&gt; RelevancePropagation.PassRule(),
    Flux.AlphaDropout       =&gt; RelevancePropagation.PassRule(),
    Flux.Dropout            =&gt; RelevancePropagation.PassRule(),
    Flux.BatchNorm          =&gt; RelevancePropagation.PassRule(),
    typeof(Flux.flatten)    =&gt; RelevancePropagation.PassRule(),
    typeof(MLUtils.flatten) =&gt; RelevancePropagation.PassRule(),
    typeof(identity)        =&gt; RelevancePropagation.PassRule(),
 ),
  FirstLayerTypeMap(  # first layer
    Flux.Conv          =&gt; RelevancePropagation.ZBoxRule{Float32}(-3.0f0, 3.0f0),
    Flux.ConvTranspose =&gt; RelevancePropagation.ZBoxRule{Float32}(-3.0f0, 3.0f0),
    Flux.CrossCor      =&gt; RelevancePropagation.ZBoxRule{Float32}(-3.0f0, 3.0f0),
 ),
)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/composite_presets.jl#L1-L9">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.EpsilonPlus" href="#RelevancePropagation.EpsilonPlus"><code>RelevancePropagation.EpsilonPlus</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">EpsilonPlus(; [epsilon=1.0f-6])</code></pre><p>Composite using the following primitives:</p><pre><code class="language-julia-repl hljs">julia&gt; EpsilonPlus()
Composite(
  GlobalTypeMap(  # all layers
    Flux.Conv               =&gt; RelevancePropagation.ZPlusRule(),
    Flux.ConvTranspose      =&gt; RelevancePropagation.ZPlusRule(),
    Flux.CrossCor           =&gt; RelevancePropagation.ZPlusRule(),
    Flux.Dense              =&gt; RelevancePropagation.EpsilonRule{Float32}(1.0f-6),
    Flux.Scale              =&gt; RelevancePropagation.EpsilonRule{Float32}(1.0f-6),
    Flux.LayerNorm          =&gt; RelevancePropagation.LayerNormRule(),
    typeof(NNlib.dropout)   =&gt; RelevancePropagation.PassRule(),
    Flux.AlphaDropout       =&gt; RelevancePropagation.PassRule(),
    Flux.Dropout            =&gt; RelevancePropagation.PassRule(),
    Flux.BatchNorm          =&gt; RelevancePropagation.PassRule(),
    typeof(Flux.flatten)    =&gt; RelevancePropagation.PassRule(),
    typeof(MLUtils.flatten) =&gt; RelevancePropagation.PassRule(),
    typeof(identity)        =&gt; RelevancePropagation.PassRule(),
 ),
)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/composite_presets.jl#L26-L34">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.EpsilonAlpha2Beta1" href="#RelevancePropagation.EpsilonAlpha2Beta1"><code>RelevancePropagation.EpsilonAlpha2Beta1</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">EpsilonAlpha2Beta1(; [epsilon=1.0f-6])</code></pre><p>Composite using the following primitives:</p><pre><code class="language-julia-repl hljs">julia&gt; EpsilonAlpha2Beta1()
Composite(
  GlobalTypeMap(  # all layers
    Flux.Conv               =&gt; RelevancePropagation.AlphaBetaRule{Float32}(2.0f0, 1.0f0),
    Flux.ConvTranspose      =&gt; RelevancePropagation.AlphaBetaRule{Float32}(2.0f0, 1.0f0),
    Flux.CrossCor           =&gt; RelevancePropagation.AlphaBetaRule{Float32}(2.0f0, 1.0f0),
    Flux.Dense              =&gt; RelevancePropagation.EpsilonRule{Float32}(1.0f-6),
    Flux.Scale              =&gt; RelevancePropagation.EpsilonRule{Float32}(1.0f-6),
    Flux.LayerNorm          =&gt; RelevancePropagation.LayerNormRule(),
    typeof(NNlib.dropout)   =&gt; RelevancePropagation.PassRule(),
    Flux.AlphaDropout       =&gt; RelevancePropagation.PassRule(),
    Flux.Dropout            =&gt; RelevancePropagation.PassRule(),
    Flux.BatchNorm          =&gt; RelevancePropagation.PassRule(),
    typeof(Flux.flatten)    =&gt; RelevancePropagation.PassRule(),
    typeof(MLUtils.flatten) =&gt; RelevancePropagation.PassRule(),
    typeof(identity)        =&gt; RelevancePropagation.PassRule(),
 ),
)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/composite_presets.jl#L50-L58">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.EpsilonPlusFlat" href="#RelevancePropagation.EpsilonPlusFlat"><code>RelevancePropagation.EpsilonPlusFlat</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">EpsilonPlusFlat(; [epsilon=1.0f-6])</code></pre><p>Composite using the following primitives:</p><pre><code class="language-julia-repl hljs">julia&gt; EpsilonPlusFlat()
Composite(
  GlobalTypeMap(  # all layers
    Flux.Conv               =&gt; RelevancePropagation.ZPlusRule(),
    Flux.ConvTranspose      =&gt; RelevancePropagation.ZPlusRule(),
    Flux.CrossCor           =&gt; RelevancePropagation.ZPlusRule(),
    Flux.Dense              =&gt; RelevancePropagation.EpsilonRule{Float32}(1.0f-6),
    Flux.Scale              =&gt; RelevancePropagation.EpsilonRule{Float32}(1.0f-6),
    Flux.LayerNorm          =&gt; RelevancePropagation.LayerNormRule(),
    typeof(NNlib.dropout)   =&gt; RelevancePropagation.PassRule(),
    Flux.AlphaDropout       =&gt; RelevancePropagation.PassRule(),
    Flux.Dropout            =&gt; RelevancePropagation.PassRule(),
    Flux.BatchNorm          =&gt; RelevancePropagation.PassRule(),
    typeof(Flux.flatten)    =&gt; RelevancePropagation.PassRule(),
    typeof(MLUtils.flatten) =&gt; RelevancePropagation.PassRule(),
    typeof(identity)        =&gt; RelevancePropagation.PassRule(),
 ),
  FirstLayerTypeMap(  # first layer
    Flux.Conv          =&gt; RelevancePropagation.FlatRule(),
    Flux.ConvTranspose =&gt; RelevancePropagation.FlatRule(),
    Flux.CrossCor      =&gt; RelevancePropagation.FlatRule(),
 ),
)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/composite_presets.jl#L74-L82">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.EpsilonAlpha2Beta1Flat" href="#RelevancePropagation.EpsilonAlpha2Beta1Flat"><code>RelevancePropagation.EpsilonAlpha2Beta1Flat</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">EpsilonAlpha2Beta1Flat(; [epsilon=1.0f-6])</code></pre><p>Composite using the following primitives:</p><pre><code class="language-julia-repl hljs">julia&gt; EpsilonAlpha2Beta1Flat()
Composite(
  GlobalTypeMap(  # all layers
    Flux.Conv               =&gt; RelevancePropagation.AlphaBetaRule{Float32}(2.0f0, 1.0f0),
    Flux.ConvTranspose      =&gt; RelevancePropagation.AlphaBetaRule{Float32}(2.0f0, 1.0f0),
    Flux.CrossCor           =&gt; RelevancePropagation.AlphaBetaRule{Float32}(2.0f0, 1.0f0),
    Flux.Dense              =&gt; RelevancePropagation.EpsilonRule{Float32}(1.0f-6),
    Flux.Scale              =&gt; RelevancePropagation.EpsilonRule{Float32}(1.0f-6),
    Flux.LayerNorm          =&gt; RelevancePropagation.LayerNormRule(),
    typeof(NNlib.dropout)   =&gt; RelevancePropagation.PassRule(),
    Flux.AlphaDropout       =&gt; RelevancePropagation.PassRule(),
    Flux.Dropout            =&gt; RelevancePropagation.PassRule(),
    Flux.BatchNorm          =&gt; RelevancePropagation.PassRule(),
    typeof(Flux.flatten)    =&gt; RelevancePropagation.PassRule(),
    typeof(MLUtils.flatten) =&gt; RelevancePropagation.PassRule(),
    typeof(identity)        =&gt; RelevancePropagation.PassRule(),
 ),
  FirstLayerTypeMap(  # first layer
    Flux.Conv          =&gt; RelevancePropagation.FlatRule(),
    Flux.ConvTranspose =&gt; RelevancePropagation.FlatRule(),
    Flux.CrossCor      =&gt; RelevancePropagation.FlatRule(),
 ),
)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/composite_presets.jl#L99-L107">source</a></section></article><h3 id="Manual-rule-assignment"><a class="docs-heading-anchor" href="#Manual-rule-assignment">Manual rule assignment</a><a id="Manual-rule-assignment-1"></a><a class="docs-heading-anchor-permalink" href="#Manual-rule-assignment" title="Permalink"></a></h3><p>For <a href="../generated/composites/#composites-manual">manual rule assignment</a>, use <code>ChainTuple</code>,  <code>ParallelTuple</code> and <code>SkipConnectionTuple</code>, matching the model structure:</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.ChainTuple" href="#RelevancePropagation.ChainTuple"><code>RelevancePropagation.ChainTuple</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ChainTuple(xs)</code></pre><p>Thin wrapper around <code>Tuple</code> for use with Flux.jl models.</p><p>Combining <a href="#RelevancePropagation.ChainTuple"><code>ChainTuple</code></a>, <a href="#RelevancePropagation.ParallelTuple"><code>ParallelTuple</code></a> and <a href="#RelevancePropagation.SkipConnectionTuple"><code>SkipConnectionTuple</code></a>, data <code>xs</code> can be stored while preserving the structure of a Flux model without risking type piracy.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/chain_utils.jl#L9-L17">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.ParallelTuple" href="#RelevancePropagation.ParallelTuple"><code>RelevancePropagation.ParallelTuple</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ParallelTuple(xs)</code></pre><p>Thin wrapper around <code>Tuple</code> for use with Flux.jl models.</p><p>Combining <a href="#RelevancePropagation.ChainTuple"><code>ChainTuple</code></a>, <a href="#RelevancePropagation.ParallelTuple"><code>ParallelTuple</code></a> and <a href="#RelevancePropagation.SkipConnectionTuple"><code>SkipConnectionTuple</code></a>, data <code>xs</code> can be stored while preserving the structure of a Flux model without risking type piracy.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/chain_utils.jl#L22-L30">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.SkipConnectionTuple" href="#RelevancePropagation.SkipConnectionTuple"><code>RelevancePropagation.SkipConnectionTuple</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">SkipConnectionTuple(xs)</code></pre><p>Thin wrapper around <code>Tuple</code> for use with Flux.jl models.</p><p>Combining <a href="#RelevancePropagation.ChainTuple"><code>ChainTuple</code></a>, <a href="#RelevancePropagation.ParallelTuple"><code>ParallelTuple</code></a> and <a href="#RelevancePropagation.SkipConnectionTuple"><code>SkipConnectionTuple</code></a>, data <code>xs</code> can be stored while preserving the structure of a Flux model without risking type piracy.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/chain_utils.jl#L35-L43">source</a></section></article><h2 id="Custom-rules"><a class="docs-heading-anchor" href="#Custom-rules">Custom rules</a><a id="Custom-rules-1"></a><a class="docs-heading-anchor-permalink" href="#Custom-rules" title="Permalink"></a></h2><p>These utilities can be used to define custom rules without writing boilerplate code. To extend these functions, explicitly <code>import</code> them: </p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.modify_input" href="#RelevancePropagation.modify_input"><code>RelevancePropagation.modify_input</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">modify_input(rule, input)</code></pre><p>Modify input activation before computing relevance propagation.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/rules.jl#L58-L62">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.modify_denominator" href="#RelevancePropagation.modify_denominator"><code>RelevancePropagation.modify_denominator</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">modify_denominator(rule, d)</code></pre><p>Modify denominator <span>$z$</span> for numerical stability on the forward pass.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/rules.jl#L65-L69">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.modify_parameters" href="#RelevancePropagation.modify_parameters"><code>RelevancePropagation.modify_parameters</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">modify_parameters(rule, parameter)</code></pre><p>Modify parameters before computing the relevance.</p><p><strong>Note</strong></p><p>Use of a custom function <code>modify_layer</code> will overwrite functionality of <code>modify_parameters</code>, <code>modify_weight</code> and <code>modify_bias</code> for the implemented combination of rule and layer types. This is due to the fact that internally, <code>modify_weight</code> and <code>modify_bias</code> are called by the default implementation of <code>modify_layer</code>. <code>modify_weight</code> and <code>modify_bias</code> in turn call <code>modify_parameters</code> by default.</p><p>The default call structure looks as follows:</p><pre><code class="nohighlight hljs">┌─────────────────────────────────────────┐
│              modify_layer               │
└─────────┬─────────────────────┬─────────┘
          │ calls               │ calls
┌─────────▼─────────┐ ┌─────────▼─────────┐
│   modify_weight   │ │    modify_bias    │
└─────────┬─────────┘ └─────────┬─────────┘
          │ calls               │ calls
┌─────────▼─────────┐ ┌─────────▼─────────┐
│ modify_parameters │ │ modify_parameters │
└───────────────────┘ └───────────────────┘</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/rules.jl#L88-L95">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.modify_weight" href="#RelevancePropagation.modify_weight"><code>RelevancePropagation.modify_weight</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">modify_weight(rule, weight)</code></pre><p>Modify layer weights before computing the relevance.</p><p><strong>Note</strong></p><p>Use of a custom function <code>modify_layer</code> will overwrite functionality of <code>modify_parameters</code>, <code>modify_weight</code> and <code>modify_bias</code> for the implemented combination of rule and layer types. This is due to the fact that internally, <code>modify_weight</code> and <code>modify_bias</code> are called by the default implementation of <code>modify_layer</code>. <code>modify_weight</code> and <code>modify_bias</code> in turn call <code>modify_parameters</code> by default.</p><p>The default call structure looks as follows:</p><pre><code class="nohighlight hljs">┌─────────────────────────────────────────┐
│              modify_layer               │
└─────────┬─────────────────────┬─────────┘
          │ calls               │ calls
┌─────────▼─────────┐ ┌─────────▼─────────┐
│   modify_weight   │ │    modify_bias    │
└─────────┬─────────┘ └─────────┬─────────┘
          │ calls               │ calls
┌─────────▼─────────┐ ┌─────────▼─────────┐
│ modify_parameters │ │ modify_parameters │
└───────────────────┘ └───────────────────┘</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/rules.jl#L98-L105">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.modify_bias" href="#RelevancePropagation.modify_bias"><code>RelevancePropagation.modify_bias</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">modify_bias(rule, bias)</code></pre><p>Modify layer bias before computing the relevance.</p><p><strong>Note</strong></p><p>Use of a custom function <code>modify_layer</code> will overwrite functionality of <code>modify_parameters</code>, <code>modify_weight</code> and <code>modify_bias</code> for the implemented combination of rule and layer types. This is due to the fact that internally, <code>modify_weight</code> and <code>modify_bias</code> are called by the default implementation of <code>modify_layer</code>. <code>modify_weight</code> and <code>modify_bias</code> in turn call <code>modify_parameters</code> by default.</p><p>The default call structure looks as follows:</p><pre><code class="nohighlight hljs">┌─────────────────────────────────────────┐
│              modify_layer               │
└─────────┬─────────────────────┬─────────┘
          │ calls               │ calls
┌─────────▼─────────┐ ┌─────────▼─────────┐
│   modify_weight   │ │    modify_bias    │
└─────────┬─────────┘ └─────────┬─────────┘
          │ calls               │ calls
┌─────────▼─────────┐ ┌─────────▼─────────┐
│ modify_parameters │ │ modify_parameters │
└───────────────────┘ └───────────────────┘</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/rules.jl#L108-L115">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.modify_layer" href="#RelevancePropagation.modify_layer"><code>RelevancePropagation.modify_layer</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">modify_layer(rule, layer)</code></pre><p>Modify layer before computing the relevance.</p><p><strong>Note</strong></p><p>Use of a custom function <code>modify_layer</code> will overwrite functionality of <code>modify_parameters</code>, <code>modify_weight</code> and <code>modify_bias</code> for the implemented combination of rule and layer types. This is due to the fact that internally, <code>modify_weight</code> and <code>modify_bias</code> are called by the default implementation of <code>modify_layer</code>. <code>modify_weight</code> and <code>modify_bias</code> in turn call <code>modify_parameters</code> by default.</p><p>The default call structure looks as follows:</p><pre><code class="nohighlight hljs">┌─────────────────────────────────────────┐
│              modify_layer               │
└─────────┬─────────────────────┬─────────┘
          │ calls               │ calls
┌─────────▼─────────┐ ┌─────────▼─────────┐
│   modify_weight   │ │    modify_bias    │
└─────────┬─────────┘ └─────────┬─────────┘
          │ calls               │ calls
┌─────────▼─────────┐ ┌─────────▼─────────┐
│ modify_parameters │ │ modify_parameters │
└───────────────────┘ └───────────────────┘</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/rules.jl#L118-L125">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.is_compatible" href="#RelevancePropagation.is_compatible"><code>RelevancePropagation.is_compatible</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">is_compatible(rule, layer)</code></pre><p>Check compatibility of a LRP-Rule with layer type.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/rules.jl#L72-L76">source</a></section></article><p>Compatibility settings:</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.LRP_CONFIG.supports_layer" href="#RelevancePropagation.LRP_CONFIG.supports_layer"><code>RelevancePropagation.LRP_CONFIG.supports_layer</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">LRP_CONFIG.supports_layer(layer)</code></pre><p>Check whether LRP can be used on a layer or a Chain. To extend LRP to your own layers, define:</p><pre><code class="language-julia hljs">LRP_CONFIG.supports_layer(::MyLayer) = true          # for structs
LRP_CONFIG.supports_layer(::typeof(mylayer)) = true  # for functions</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/checks.jl#L5-L14">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.LRP_CONFIG.supports_activation" href="#RelevancePropagation.LRP_CONFIG.supports_activation"><code>RelevancePropagation.LRP_CONFIG.supports_activation</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">LRP_CONFIG.supports_activation(σ)</code></pre><p>Check whether LRP can be used on a given activation function. To extend LRP to your own activation functions, define:</p><pre><code class="language-julia hljs">LRP_CONFIG.supports_activation(::typeof(myactivation)) = true  # for functions
LRP_CONFIG.supports_activation(::MyActivation) = true          # for structs</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/checks.jl#L17-L26">source</a></section></article><h2 id="CRP"><a class="docs-heading-anchor" href="#CRP">CRP</a><a id="CRP-1"></a><a class="docs-heading-anchor-permalink" href="#CRP" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RelevancePropagation.CRP" href="#RelevancePropagation.CRP"><code>RelevancePropagation.CRP</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">CRP(lrp_analyzer, layer, features)</code></pre><p>Use Concept Relevance Propagation to explain the output of a neural network with respect to specific features in a given layer.</p><p><strong>Arguments</strong></p><ul><li><code>lrp_analyzer::LRP</code>: LRP analyzer</li><li><code>layer::Int</code>: Index of layer after which the concept is located</li><li><code>features</code>: Concept / feature to explain.</li></ul><p>See also <a href="#XAIBase.TopNFeatures"><code>TopNFeatures</code></a> and <a href="#XAIBase.IndexedFeatures"><code>IndexedFeatures</code></a>.</p><p><strong>References</strong></p><p>[1] R. Achtibat et al., From attribution maps to human-understandable explanations     through Concept Relevance Propagation</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/RelevancePropagation.jl/blob/e6d86e1bcfbb2634b02e153535e8ef8e70ea7078/src/crp.jl#L1-L17">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="XAIBase.TopNFeatures" href="#XAIBase.TopNFeatures"><code>XAIBase.TopNFeatures</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">TopNFeatures(n)</code></pre><p>Select top-n features.</p><p>For outputs of convolutional layers, the relevance is summed across height and width channels for each feature.</p><p>See also <a href="#XAIBase.IndexedFeatures"><code>IndexedFeatures</code></a>.</p><p><strong>Note</strong></p><p>The XAIBase interface currently assumes that features have either 2 or 4 dimensions (<code>(features, batchsize)</code> or <code>(width, height, features, batchsize)</code>).</p><p>It also assumes that the batch dimension is the last dimension of the feature.</p><p><strong>Example</strong></p><pre><code class="language-julia-repl hljs">julia&gt; feature_selector = TopNFeatures(2)
 TopNFeatures(2)

julia&gt; feature = rand(3, 2)
3×2 Matrix{Float64}:
 0.265312  0.953689
 0.674377  0.172154
 0.649722  0.570809

julia&gt; feature_selector(feature)
2-element Vector{Vector{CartesianIndices{2, Tuple{UnitRange{Int64}, UnitRange{Int64}}}}}:
 [CartesianIndices((2:2, 1:1)), CartesianIndices((1:1, 2:2))]
 [CartesianIndices((3:3, 1:1)), CartesianIndices((3:3, 2:2))]

julia&gt; feature = rand(3, 3, 3, 2);

julia&gt; feature_selector(feature)
2-element Vector{Vector{CartesianIndices{4, NTuple{4, UnitRange{Int64}}}}}:
 [CartesianIndices((1:3, 1:3, 2:2, 1:1)), CartesianIndices((1:3, 1:3, 1:1, 2:2))]
 [CartesianIndices((1:3, 1:3, 1:1, 1:1)), CartesianIndices((1:3, 1:3, 3:3, 2:2))]</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/XAIBase.jl/blob/v3.0.0/src/feature_selection.jl#L83-L118">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="XAIBase.IndexedFeatures" href="#XAIBase.IndexedFeatures"><code>XAIBase.IndexedFeatures</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">IndexedFeatures(indices...)</code></pre><p>Select features by indices.</p><p>For outputs of convolutional layers, the index refers to a feature dimension.</p><p>See also See also <a href="#XAIBase.TopNFeatures"><code>TopNFeatures</code></a>.</p><p><strong>Note</strong></p><p>The XAIBase interface currently assumes that features have either 2 or 4 dimensions (<code>(features, batchsize)</code> or <code>(width, height, features, batchsize)</code>).</p><p>It also assumes that the batch dimension is the last dimension of the feature.</p><p><strong>Example</strong></p><pre><code class="language-julia-repl hljs">julia&gt; feature_selector = IndexedFeatures(2, 3)
 IndexedFeatures(2, 3)

julia&gt; feature = rand(3, 3, 3, 2);

julia&gt; feature_selector(feature)
2-element Vector{Vector{CartesianIndices{4, NTuple{4, UnitRange{Int64}}}}}:
 [CartesianIndices((1:3, 1:3, 2:2, 1:1)), CartesianIndices((1:3, 1:3, 2:2, 2:2))]
 [CartesianIndices((1:3, 1:3, 3:3, 1:1)), CartesianIndices((1:3, 1:3, 3:3, 2:2))]

julia&gt; feature = rand(3, 2);

julia&gt; feature_selector(feature)
 1-element Vector{Vector{CartesianIndices{2, Tuple{UnitRange{Int64}, UnitRange{Int64}}}}}:
  [CartesianIndices((2:2, 1:1)), CartesianIndices((2:2, 2:2))]</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Julia-XAI/XAIBase.jl/blob/v3.0.0/src/feature_selection.jl#L24-L53">source</a></section></article><h1 id="Index"><a class="docs-heading-anchor" href="#Index">Index</a><a id="Index-1"></a><a class="docs-heading-anchor-permalink" href="#Index" title="Permalink"></a></h1><ul><li><a href="#RelevancePropagation.AlphaBetaRule"><code>RelevancePropagation.AlphaBetaRule</code></a></li><li><a href="#RelevancePropagation.CRP"><code>RelevancePropagation.CRP</code></a></li><li><a href="#RelevancePropagation.ChainTuple"><code>RelevancePropagation.ChainTuple</code></a></li><li><a href="#RelevancePropagation.Composite"><code>RelevancePropagation.Composite</code></a></li><li><a href="#RelevancePropagation.ConvLayer"><code>RelevancePropagation.ConvLayer</code></a></li><li><a href="#RelevancePropagation.DropoutLayer"><code>RelevancePropagation.DropoutLayer</code></a></li><li><a href="#RelevancePropagation.EpsilonRule"><code>RelevancePropagation.EpsilonRule</code></a></li><li><a href="#RelevancePropagation.FirstLayerMap"><code>RelevancePropagation.FirstLayerMap</code></a></li><li><a href="#RelevancePropagation.FirstLayerTypeMap"><code>RelevancePropagation.FirstLayerTypeMap</code></a></li><li><a href="#RelevancePropagation.FirstNTypeMap"><code>RelevancePropagation.FirstNTypeMap</code></a></li><li><a href="#RelevancePropagation.FlatRule"><code>RelevancePropagation.FlatRule</code></a></li><li><a href="#RelevancePropagation.GammaRule"><code>RelevancePropagation.GammaRule</code></a></li><li><a href="#RelevancePropagation.GeneralizedGammaRule"><code>RelevancePropagation.GeneralizedGammaRule</code></a></li><li><a href="#RelevancePropagation.GlobalMap"><code>RelevancePropagation.GlobalMap</code></a></li><li><a href="#RelevancePropagation.GlobalTypeMap"><code>RelevancePropagation.GlobalTypeMap</code></a></li><li><a href="#RelevancePropagation.LRP"><code>RelevancePropagation.LRP</code></a></li><li><a href="#RelevancePropagation.LastLayerMap"><code>RelevancePropagation.LastLayerMap</code></a></li><li><a href="#RelevancePropagation.LastLayerTypeMap"><code>RelevancePropagation.LastLayerTypeMap</code></a></li><li><a href="#RelevancePropagation.LayerMap"><code>RelevancePropagation.LayerMap</code></a></li><li><a href="#RelevancePropagation.LayerNormRule"><code>RelevancePropagation.LayerNormRule</code></a></li><li><a href="#RelevancePropagation.NormalizationLayer"><code>RelevancePropagation.NormalizationLayer</code></a></li><li><a href="#RelevancePropagation.ParallelTuple"><code>RelevancePropagation.ParallelTuple</code></a></li><li><a href="#RelevancePropagation.PassRule"><code>RelevancePropagation.PassRule</code></a></li><li><a href="#RelevancePropagation.PoolingLayer"><code>RelevancePropagation.PoolingLayer</code></a></li><li><a href="#RelevancePropagation.RangeMap"><code>RelevancePropagation.RangeMap</code></a></li><li><a href="#RelevancePropagation.RangeTypeMap"><code>RelevancePropagation.RangeTypeMap</code></a></li><li><a href="#RelevancePropagation.ReshapingLayer"><code>RelevancePropagation.ReshapingLayer</code></a></li><li><a href="#RelevancePropagation.SkipConnectionTuple"><code>RelevancePropagation.SkipConnectionTuple</code></a></li><li><a href="#RelevancePropagation.WSquareRule"><code>RelevancePropagation.WSquareRule</code></a></li><li><a href="#RelevancePropagation.ZBoxRule"><code>RelevancePropagation.ZBoxRule</code></a></li><li><a href="#RelevancePropagation.ZPlusRule"><code>RelevancePropagation.ZPlusRule</code></a></li><li><a href="#RelevancePropagation.ZeroRule"><code>RelevancePropagation.ZeroRule</code></a></li><li><a href="#XAIBase.Explanation"><code>XAIBase.Explanation</code></a></li><li><a href="#XAIBase.IndexedFeatures"><code>XAIBase.IndexedFeatures</code></a></li><li><a href="#XAIBase.TopNFeatures"><code>XAIBase.TopNFeatures</code></a></li><li><a href="#RelevancePropagation.EpsilonAlpha2Beta1"><code>RelevancePropagation.EpsilonAlpha2Beta1</code></a></li><li><a href="#RelevancePropagation.EpsilonAlpha2Beta1Flat"><code>RelevancePropagation.EpsilonAlpha2Beta1Flat</code></a></li><li><a href="#RelevancePropagation.EpsilonGammaBox"><code>RelevancePropagation.EpsilonGammaBox</code></a></li><li><a href="#RelevancePropagation.EpsilonPlus"><code>RelevancePropagation.EpsilonPlus</code></a></li><li><a href="#RelevancePropagation.EpsilonPlusFlat"><code>RelevancePropagation.EpsilonPlusFlat</code></a></li><li><a href="#RelevancePropagation.LRP_CONFIG.supports_activation"><code>RelevancePropagation.LRP_CONFIG.supports_activation</code></a></li><li><a href="#RelevancePropagation.LRP_CONFIG.supports_layer"><code>RelevancePropagation.LRP_CONFIG.supports_layer</code></a></li><li><a href="#RelevancePropagation.canonize"><code>RelevancePropagation.canonize</code></a></li><li><a href="#RelevancePropagation.flatten_model"><code>RelevancePropagation.flatten_model</code></a></li><li><a href="#RelevancePropagation.is_compatible"><code>RelevancePropagation.is_compatible</code></a></li><li><a href="#RelevancePropagation.lrp_rules"><code>RelevancePropagation.lrp_rules</code></a></li><li><a href="#RelevancePropagation.modify_bias"><code>RelevancePropagation.modify_bias</code></a></li><li><a href="#RelevancePropagation.modify_denominator"><code>RelevancePropagation.modify_denominator</code></a></li><li><a href="#RelevancePropagation.modify_input"><code>RelevancePropagation.modify_input</code></a></li><li><a href="#RelevancePropagation.modify_layer"><code>RelevancePropagation.modify_layer</code></a></li><li><a href="#RelevancePropagation.modify_parameters"><code>RelevancePropagation.modify_parameters</code></a></li><li><a href="#RelevancePropagation.modify_weight"><code>RelevancePropagation.modify_weight</code></a></li><li><a href="#RelevancePropagation.show_layer_indices"><code>RelevancePropagation.show_layer_indices</code></a></li><li><a href="#RelevancePropagation.strip_softmax"><code>RelevancePropagation.strip_softmax</code></a></li><li><a href="#XAIBase.analyze"><code>XAIBase.analyze</code></a></li></ul></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../rules/">« LRP Rule Overview</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.3.0 on <span class="colophon-date" title="Monday 18 March 2024 17:34">Monday 18 March 2024</span>. Using Julia version 1.10.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
